{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from konlpy.tag import Kkma\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "kkma = Kkma() # use KKMA Morphological Analyzer\n",
    "\n",
    "f = open(\"불용어 리스트.txt\",'r', encoding='utf8') # stopword list\n",
    "stop_words = f.read()\n",
    "stop_words = stop_words.split('\\n')\n",
    "\n",
    "## Preprocess function ( This function is used in every preprcess in this program )\n\n",
    "def preprocessing(text):\n",
    "    text = text.replace('ㅋ','').replace('ㅠ','').replace('ㅜ','') # delete 'ㅋ', 'ㅠ', 'ㅜ'\n",
    "    \n",
    "    text_pos = kkma.pos(text)\n",
    "    text_morphs = kkma.morphs(text)\n",
    "    \n",
    "    words = []\n",
    "    tags = ['NNG','NNP','NNB','NNM','NP','VV','VA','VXV','VXA','MDT','MDN','MAG','MAC','UN','XR'] # tag\n",
    "    \n",
    "    # Create a word list corresponding to the part-of-speech tag to use\n",
    "    for word, tag in text_pos:\n",
    "        if tag in tags:\n",
    "            words.append(word)\n",
    "            \n",
    "    # Clear stopwords\n",
    "    result = []\n",
    "    for w in words: \n",
    "        if w not in stop_words: \n",
    "            result.append(w)\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_title={1:\"겟아웃\",2:\"부산행\",3:\"서치\",4:\"해피데스데이\",5:\"곡성\"}\n",
    "for i in range(len(movie_title)):\n",
    "    rtitle = \"%s_최종본.csv\" %(movie_title[i+1])\n",
    "    wtitle = \"%s_tf.csv\" %(movie_title[i+1])\n",
    "\n",
    "    blog = open(rtitle, 'r')\n",
    "    rblog = csv.reader(blog)\n",
    "    next(rblog) # skip header\n",
    "    \n",
    "    # Preprocess\n",
    "    total=[]\n",
    "    for line in rblog:\n",
    "        total.extend(preprocessing(line[2])) # total words in Naver blog review\n",
    "   \n",
    "    # Term Frequency\n",
    "    tf=[]\n",
    "    countWord = Counter(total)\n",
    "    for key in countWord:\n",
    "        tf.append([key, round(1+math.log(countWord[key],2),2)])  \n",
    "    \n",
    "    # Write tf CSV File\n",
    "    tfcsv = open(wtitle, 'w', newline='')\n",
    "    wr = csv.writer(tfcsv)\n",
    "    wr.writerow([\"word\",\"tf\"])\n",
    "    for i in range(len(tf)):\n",
    "        wr.writerow(tf[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
